{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8484d4f6-27de-430b-82e4-f334034695ab",
   "metadata": {},
   "source": [
    "#### 1. Perform future engineering on fixtures data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c05b28f-39f8-4548-b115-3277ed482a8e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def add_statistics(fixtures_df):\n",
    "    \n",
    "    fixtures_df['fixture_date'] = pd.to_datetime(fixtures_df['fixture_date']).dt.date\n",
    "    fixtures_df = fixtures_df.sort_values(by='fixture_date')\n",
    "    fixtures_df['teams_home_goals_scored_home'] = fixtures_df.groupby(['league_season', 'teams_home_id'])['goals_home'].cumsum()\n",
    "    fixtures_df['teams_away_goals_scored_away'] = fixtures_df.groupby(['league_season','teams_away_id'])['goals_away'].cumsum()\n",
    "    fixtures_df['teams_home_goals_lost_home'] = fixtures_df.groupby(['league_season','teams_home_id'])['goals_away'].cumsum()\n",
    "    fixtures_df['teams_away_goals_lost_away'] = fixtures_df.groupby(['league_season','teams_away_id'])['goals_home'].cumsum()\n",
    "    fixtures_df['teams_home_winner'] = fixtures_df.apply(\n",
    "        lambda row: 3 if row['score_fulltime_home']>row['score_fulltime_away'] else (1 if row['score_fulltime_home']==row['score_fulltime_away'] else 0), axis=1\n",
    "    )\n",
    "    fixtures_df['teams_away_winner'] = fixtures_df.apply(\n",
    "        lambda row: 3 if row['score_fulltime_home']<row['score_fulltime_away'] else (1 if row['score_fulltime_home']==row['score_fulltime_away'] else 0), axis=1\n",
    "    )\n",
    "    home = fixtures_df[[\n",
    "        'fixture_date',\n",
    "        'league_season',\n",
    "        'teams_home_id', \n",
    "        'goals_home',\n",
    "        'goals_away',\n",
    "        'teams_home_winner', \n",
    "        'league_round'\n",
    "        ]].rename(columns={\n",
    "        'teams_home_id':'team_id',\n",
    "        'goals_home':'goals_scored',\n",
    "        'goals_away':'goals_lost',\n",
    "        'teams_home_winner':'points'\n",
    "        })\n",
    "    away = fixtures_df[[\n",
    "        'fixture_date', \n",
    "        'league_season',\n",
    "        'teams_away_id', \n",
    "        'goals_away',\n",
    "        'goals_home',\n",
    "        'teams_away_winner', \n",
    "        'league_round'\n",
    "        ]].rename(columns={\n",
    "        'teams_away_id':'team_id', \n",
    "        'goals_away':'goals_scored',\n",
    "        'goals_home':'goals_lost',\n",
    "        'teams_away_winner':'points'\n",
    "        })\n",
    "\n",
    "    total = pd.concat([home, away])\n",
    "    total = total.sort_values(by='fixture_date')\n",
    "    total['total_goals_scored'] = total.groupby(['league_season','team_id'])['goals_scored'].cumsum()\n",
    "    total['total_goals_lost'] = total.groupby(['league_season','team_id'])['goals_lost'].cumsum()\n",
    "    total = total.sort_values(by='fixture_date')\n",
    "\n",
    "    total['total_points'] = total.groupby(['league_season','team_id'])['points'].cumsum()\n",
    "\n",
    "    total.sort_values(by=['league_season','league_round','total_points','total_goals_scored','fixture_date'], ascending=[True,True,False,False,True])\n",
    "    total['standings'] = total.groupby(['league_season','league_round'])['total_points'].rank(method='min', ascending=False)\n",
    "    total['standings'] = total['standings'].astype(int)\n",
    "\n",
    "    total = total.sort_values(by=['team_id','fixture_date'])\n",
    "    total['points_last_5_matches'] = total.groupby('team_id')['points'].rolling(window=5, min_periods=1).sum().reset_index(level=0, drop=True)\n",
    "    total['points_last_5_matches'] = total['points_last_5_matches'].fillna(0)\n",
    "    total['points_last_5_matches'] = total['points_last_5_matches'].astype(int)\n",
    "\n",
    "    fixtures_df = fixtures_df.merge(total[[\n",
    "        'fixture_date',\n",
    "        'team_id',\n",
    "        'total_goals_scored',\n",
    "        'total_goals_lost', \n",
    "        'points', \n",
    "        'total_points', \n",
    "        'standings',\n",
    "        'points_last_5_matches'\n",
    "        ]], left_on = [\n",
    "            'fixture_date',\n",
    "            'teams_home_id'\n",
    "            ],right_on = [\n",
    "            'fixture_date',\n",
    "            'team_id'\n",
    "            ], how='left'\n",
    "            ).rename(columns={\n",
    "                'total_goals_scored':'teams_home_total_goals_scored',\n",
    "                'total_goals_lost':'teams_home_total_goals_lost',\n",
    "                'points':'teams_home_points',\n",
    "                'total_points':'teams_home_total_points',\n",
    "                'standings':'teams_home_standings',\n",
    "                'points_last_5_matches':'teams_home_last_five_matches_points'\n",
    "            }).drop(columns='team_id')\n",
    "    \n",
    "    fixtures_df = fixtures_df.merge(total[[\n",
    "        'fixture_date',\n",
    "        'team_id',\n",
    "        'total_goals_scored',\n",
    "        'total_goals_lost', \n",
    "        'points', \n",
    "        'total_points', \n",
    "        'standings',\n",
    "        'points_last_5_matches'\n",
    "        ]], left_on = [\n",
    "            'fixture_date',\n",
    "            'teams_away_id'\n",
    "            ],right_on = [\n",
    "            'fixture_date',\n",
    "            'team_id'\n",
    "            ], how='left'\n",
    "            ).rename(columns={\n",
    "                'total_goals_scored':'teams_away_total_goals_scored',\n",
    "                'total_goals_lost':'teams_away_total_goals_lost',\n",
    "                'points':'teams_away_points',\n",
    "                'total_points':'teams_away_total_points',\n",
    "                'standings':'teams_away_standings',\n",
    "                'points_last_5_matches':'teams_away_last_five_matches_points'\n",
    "            }).drop(columns='team_id')\n",
    "\n",
    "    return fixtures_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dff1940-651c-46e8-8a68-765204a81ce3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# add stats to fixtures table and save it in fixtures update table\n",
    "def future_engineering():\n",
    "    conn = None\n",
    "    cur = None\n",
    "    fixtures_df = None\n",
    "    conflict_columns = ['fixture_id']\n",
    "    db_params = {\n",
    "        'host': 'localhost',\n",
    "        'database': 'preds',\n",
    "        'user': 'postgres',\n",
    "        'password': 'pass',\n",
    "        'port': '5432'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        conn = None\n",
    "        cur = None \n",
    "    \n",
    "        conn = psycopg2.connect(**db_params)\n",
    "        cur = conn.cursor()\n",
    "        \n",
    "\n",
    "        query = \"\"\"\n",
    "            SELECT *\n",
    "            FROM fixtures\n",
    "            WHERE fixture_status_short IN ('FT', 'WO', 'AET', 'PEN', 'CANC')\n",
    "        \"\"\"\n",
    "        \n",
    "        fixtures_df = pd.read_sql_query(query, conn)\n",
    "        \n",
    "        df = add_statistics(fixtures_df)\n",
    "        \n",
    "        update_columns = [col for col in df.columns if col not in conflict_columns]\n",
    "        #insert data into tables\n",
    "\n",
    "        update_set = ', '.join([f\"{col} = EXCLUDED.{col}\" for col in update_columns])\n",
    "        insert_query = \"\"\"\n",
    "            INSERT INTO {} ({})\n",
    "            VALUES ({})\n",
    "            ON CONFLICT ({}) DO UPDATE SET {}\n",
    "        \"\"\".format('fixtures_updated', ','.join(df.columns), ','.join(['%s']*len(df.columns)), ','.join(conflict_columns), update_set)\n",
    "\n",
    "        cur.executemany(insert_query, df.values.tolist())\n",
    "        print(f'table fixtures_updated updated')\n",
    "        \n",
    "        # Commit the changes\n",
    "        conn.commit()\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f'Error {e}')\n",
    "        if conn is not None:\n",
    "            conn.rollback()\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            # Close the cursor and connection\n",
    "            cur.close()\n",
    "        if cur is not None:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7531b4-6e62-4eef-8cc3-ef3c3394e391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "df = future_engineering()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bdb4c8-c0ae-4f5e-aedb-c2f4d5ece135",
   "metadata": {},
   "source": [
    "#### 2. Get updated data and preprocess it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1152169d-d145-4ab3-bd1b-53478bd715c6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# add stats to fixtures table and save it in fixtures update table\n",
    "def get_updated_matches()\n",
    "    conn = None\n",
    "    cur = None\n",
    "    fixtures_df = None\n",
    "    conflict_columns = ['fixture_id']\n",
    "    db_params = {\n",
    "        'host': 'localhost',\n",
    "        'database': 'preds',\n",
    "        'user': 'postgres',\n",
    "        'password': 'pass',\n",
    "        'port': '5432'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        conn = None\n",
    "        cur = None \n",
    "    \n",
    "        conn = psycopg2.connect(**db_params)\n",
    "        cur = conn.cursor()\n",
    "        \n",
    "        query = \"\"\"\n",
    "            SELECT *\n",
    "            FROM fixtures_updated\n",
    "        \"\"\"\n",
    "        \n",
    "        fixtures_df = pd.read_sql_query(query, conn)\n",
    "        return fixtures_df\n",
    "    except Exception as e:\n",
    "        print(f'Error {e}')\n",
    "    \n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            # Close the cursor and connection\n",
    "            cur.close()\n",
    "        if cur is not None:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07557101-ae28-45cb-82b6-138895fd3565",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixtures_df = get_updated_matches()\n",
    "s_path = 'data/contests.csv'\n",
    "seasons = pd.read_csv(s_path)\n",
    "\n",
    "fixtures_df['fixture_date'] = pd.to_datetime(fixtures_df['fixture_date'])\n",
    "fixtures_df['day_of_week'] = fixtures_df['fixture_date'].dt.dayofweek\n",
    "fixtures_df = fixtures_df.merge(seasons[['league_id','type']], on='league_id', how='left')\n",
    "\n",
    "fixtures_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664060c5-c653-4f8a-b988-ce8f5ff9546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(fixtures_df['type'])\n",
    "fixtures_df['league_type_encoded'] = label_encoder.transform(fixtures_df['type'])\n",
    "\n",
    "joblib.dump(label_encoder, 'apache_airflow/models/label_encoder_league_type.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169dd294-ceaf-4986-bf82-a8fe4f567465",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_goals = fixtures_df[[\n",
    "    'fixture_id',\n",
    "    'day_of_week', \n",
    "    'league_id', \n",
    "    'league_round',\n",
    "    'league_type_encoded',\n",
    "    'teams_home_id',\n",
    "    'teams_home_total_goals_scored',\n",
    "    'teams_home_total_goals_lost',\n",
    "    'teams_home_last_five_matches_points',\n",
    "    'teams_home_goals_scored_home',\n",
    "    'teams_home_goals_lost_home',\n",
    "    'teams_away_id',\n",
    "    'teams_away_total_goals_scored',\n",
    "    'teams_away_total_goals_lost',\n",
    "    'teams_away_last_five_matches_points',\n",
    "    'teams_away_goals_scored_away',\n",
    "    'teams_away_goals_lost_away',\n",
    "    'goals_home',\n",
    "    'goals_away'\n",
    "]]\n",
    "\n",
    "df_goals['home_over_1'] = df_goals['goals_home'].apply(lambda x: 1 if x > 1 else 0)\n",
    "df_goals['home_over_2'] = df_goals['goals_home'].apply(lambda x: 1 if x > 2 else 0)\n",
    "\n",
    "df_goals['away_over_1'] = df_goals['goals_away'].apply(lambda x: 1 if x > 1 else 0)\n",
    "df_goals['away_over_2'] = df_goals['goals_away'].apply(lambda x: 1 if x > 2 else 0)\n",
    "\n",
    "df_goals['both_scores'] = df_goals.apply(lambda row: 1 if (row['goals_home']>0)&(row['goals_away']>0) else 0, axis=1)\n",
    "df_goals['over_1'] = df_goals.apply(lambda row: 1 if row['goals_home']+row['goals_away']>1 else 0, axis=1)\n",
    "df_goals['over_2'] = df_goals.apply(lambda row: 1 if row['goals_home']+row['goals_away']>2 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5de211-e418-4b35-978c-8bb8ae6bed17",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_result = fixtures_df[[\n",
    "    'fixture_id',\n",
    "    'day_of_week', \n",
    "    'league_id', \n",
    "    'league_type_encoded',\n",
    "    'teams_home_id',\n",
    "    'teams_home_total_goals_scored',\n",
    "    'teams_home_total_goals_lost',\n",
    "    'teams_home_last_five_matches_points',\n",
    "    'teams_home_goals_scored_home',\n",
    "    'teams_home_goals_lost_home',\n",
    "    'teams_home_total_points',\n",
    "    'teams_home_standings',\n",
    "    'score_halftime_home',\n",
    "    'teams_away_id',\n",
    "    'teams_away_total_goals_scored',\n",
    "    'teams_away_total_goals_lost',\n",
    "    'teams_away_last_five_matches_points',\n",
    "    'teams_away_goals_scored_away',\n",
    "    'teams_away_goals_lost_away',\n",
    "    'teams_away_total_points',\n",
    "    'teams_away_standings',\n",
    "    'score_halftime_away',\n",
    "    'goals_home',\n",
    "    'goals_away'\n",
    "]]\n",
    "\n",
    "df_result['result'] = df_result.apply(\n",
    "    lambda row: 0 if row['goals_home']>row['goals_away'] else (\n",
    "        1 if row['goals_home']==row['goals_away'] else 2\n",
    "    ), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_result['result_double_chance_home'] = df_result.apply(\n",
    "    lambda row: 1 if row['goals_home']>=row['goals_away'] else 0,\n",
    "    axis=1\n",
    ")\n",
    "df_result['result_double_chance_away'] = df_result.apply(\n",
    "    lambda row: 1 if row['goals_away']>=row['goals_home'] else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_result['result_first_half'] = df_result.apply(\n",
    "    lambda row: 0 if row['score_halftime_home']>row['score_halftime_away'] else (\n",
    "        1 if row['score_halftime_home']==row['score_halftime_away'] else 2\n",
    "    ), \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b54c0bf-8f89-4844-8f5a-21de9d82da03",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 3. Add class saving training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27db5a51-d163-4e2e-b538-8f09d6e8276d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class MetricsCallback(Callback):\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        self.epoch_metrics = {}\n",
    "        self.params_list = [params]\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.epoch_metrics = {}\n",
    "        self.params_list.append(self.params)\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        for key, value in logs.items():\n",
    "            if key.endswith('_accuracy') or key.endswith('loss'):\n",
    "                if key not in self.epoch_metrics:\n",
    "                    self.epoch_metrics[key] = {'accuracy': [], 'loss': []}\n",
    "                if key.endswith('_accuracy'):\n",
    "                    self.epoch_metrics[key]['accuracy'].append(value)\n",
    "                elif key.endswith('loss'):\n",
    "                    self.epoch_metrics[key]['loss'].append(value)\n",
    "   \n",
    "    def get_metrics(self):\n",
    "        return self.epoch_metrics\n",
    "    \n",
    "    def get_training_data(self):\n",
    "        return self.params_list, self.epoch_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef6a585-6dd9-4289-8f27-440c891e4ff5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 4. Learning goals model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f572dec-f7e8-44cb-9cab-2b655b1e79f8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def define_model(numerical_inp = 15):\n",
    "\n",
    "    # Label Encoding\n",
    "    input_numerical = Input(shape=(numerical_inp,), name = 'input_numerical')\n",
    "    \n",
    "    # \n",
    "    dense1 = Dense(64, activation='relu')(input_numerical)\n",
    "    dense2 = Dense(32, activation='relu')(dense1)\n",
    "    \n",
    "    # results\n",
    "    output1 = Dense(1, activation='sigmoid', name='home_over_1')(dense2)\n",
    "    output2 = Dense(1, activation='sigmoid', name='home_over_2')(dense2)\n",
    "    output3 = Dense(1, activation='sigmoid', name='away_over_1')(dense2)\n",
    "    output4 = Dense(1, activation='sigmoid', name='away_over_2')(dense2)\n",
    "    output5 = Dense(1, activation='sigmoid', name='both_scores')(dense2)\n",
    "    \n",
    "    # layer use\n",
    "    model = Model(inputs=[input_numerical], outputs=[output1, output2, output3, output4, output5])\n",
    "\n",
    "    return model\n",
    "    \n",
    "def training(model, X, y_1, y_2, y_3, y_4, y_5, **params):\n",
    "    tf.keras.backend.clear_session()\n",
    "    metrics_callback = MetricsCallback(params=params)\n",
    "    model.compile(optimizer=Adam(learning_rate=params['learning_rate']),\n",
    "                 loss={\n",
    "                     'home_over_1': 'binary_crossentropy', \n",
    "                     'home_over_2': 'binary_crossentropy', \n",
    "                     'away_over_1': 'binary_crossentropy',\n",
    "                     'away_over_2': 'binary_crossentropy',\n",
    "                     'both_scores': 'binary_crossentropy'\n",
    "                 },\n",
    "                  metrics={\n",
    "                     'home_over_1': 'accuracy', \n",
    "                     'home_over_2': 'accuracy', \n",
    "                     'away_over_1': 'accuracy', \n",
    "                     'away_over_2': 'accuracy', \n",
    "                     'both_scores': 'accuracy',\n",
    "                  })\n",
    "    \n",
    "    model.fit(X,\n",
    "              {\n",
    "                  'home_over_1':y_1, \n",
    "                  'home_over_2':y_2, \n",
    "                  'away_over_1':y_3, \n",
    "                  'away_over_2':y_4, \n",
    "                  'both_scores':y_5\n",
    "              },\n",
    "              epochs = params['epochs'], \n",
    "              batch_size = params['batch_size'], \n",
    "              validation_split = params['validation_split'],\n",
    "              verbose = 1, \n",
    "              callbacks=[metrics_callback])\n",
    "    \n",
    "    params_list, metrics_list = metrics_callback.get_training_data()\n",
    "    return params_list, metrics_list, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d442cdab-7927-4433-ab3f-e52edec79fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "numerical_inp = 15\n",
    "\n",
    "X = df_goals[[\n",
    "    'day_of_week', \n",
    "    'league_id', \n",
    "    'league_type_encoded', \n",
    "    'teams_home_id', \n",
    "    'teams_home_total_goals_scored',\n",
    "    'teams_home_total_goals_lost', \n",
    "    'teams_home_last_five_matches_points',\n",
    "    'teams_home_goals_scored_home', \n",
    "    'teams_home_goals_lost_home',\n",
    "    'teams_away_id', \n",
    "    'teams_away_total_goals_scored',\n",
    "    'teams_away_total_goals_lost', \n",
    "    'teams_away_last_five_matches_points',\n",
    "    'teams_away_goals_scored_away', \n",
    "    'teams_away_goals_lost_away'\n",
    "]]\n",
    "\n",
    "y_1 = df_goals['home_over_1']\n",
    "y_2 = df_goals['home_over_2']\n",
    "y_3 = df_goals['away_over_1']\n",
    "y_4 = df_goals['away_over_2']\n",
    "y_5 = df_goals['both_scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c291ab2-1b59-4ef9-a5ad-5608c32187e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'validation_split': 0.15,\n",
    "    'optimizer': 'adam',\n",
    "    'batch_size': 32,\n",
    "    'epochs': 12,\n",
    "    'learning_rate': 0.001\n",
    "}\n",
    "\n",
    "b_goal_model = define_model()\n",
    "returned_params, returned_metrics, goal_model = training(model=b_goal_model, X=X, y_1=y_1, y_2=y_2, y_3=y_3, y_4=y_4, y_5=y_5, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa1c556-25a1-4b0e-acdf-0944fdc7b23c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 5. Learning result model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3e10f8-5c45-490d-8e6e-b2c50bfc1a2f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def define_rm_model(numerical_inp = 19):\n",
    "\n",
    "    # Label Encoding\n",
    "    input_numerical = Input(shape=(numerical_inp,), name = 'input_numerical')\n",
    "    \n",
    "    # \n",
    "    dense1 = Dense(64, activation='relu')(input_numerical)\n",
    "    dense2 = Dense(32, activation='relu')(dense1)\n",
    "    \n",
    "    # results\n",
    "    output1 = Dense(3, activation='softmax', name='result')(dense2)\n",
    "    output2 = Dense(3, activation='softmax', name='result_first_half')(dense2)\n",
    "    output3 = Dense(1, activation='sigmoid', name='result_double_chance_home')(dense2)\n",
    "    output4 = Dense(1, activation='sigmoid', name='result_double_chance_away')(dense2)\n",
    "    \n",
    "    # layer use\n",
    "    model = Model(inputs=[input_numerical], outputs=[output1, output2, output3, output4])\n",
    "\n",
    "    return model\n",
    "    \n",
    "def training_rm(model, X, y_1, y_2, y_3, y_4, **params):\n",
    "    tf.keras.backend.clear_session()\n",
    "    metrics_callback = MetricsCallback(params=params)\n",
    "    model.compile(optimizer=Adam(learning_rate=params['learning_rate']),\n",
    "                 loss={\n",
    "                     'result': 'sparse_categorical_crossentropy',\n",
    "                     'result_first_half': 'sparse_categorical_crossentropy',\n",
    "                     'result_double_chance_home': 'binary_crossentropy',\n",
    "                     'result_double_chance_away': 'binary_crossentropy'\n",
    "                 },\n",
    "                  metrics={\n",
    "                     'result': 'accuracy',\n",
    "                     'result_first_half': 'accuracy',\n",
    "                     'result_double_chance_home': 'accuracy',\n",
    "                     'result_double_chance_away': 'accuracy'\n",
    "                  })\n",
    "    \n",
    "    model.fit(X,\n",
    "              {\n",
    "                 'result': y_1,\n",
    "                 'result_first_half': y_2,\n",
    "                 'result_double_chance_home': y_3,\n",
    "                 'result_double_chance_away': y_4\n",
    "              },\n",
    "              epochs = params['epochs'], \n",
    "              batch_size = params['batch_size'], \n",
    "              validation_split = params['validation_split'],\n",
    "              verbose = 1, \n",
    "              callbacks=[metrics_callback])\n",
    "    \n",
    "    params_list, metrics_list = metrics_callback.get_training_data()\n",
    "    return params_list, metrics_list, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ca031f-48b1-41af-afa7-3654a7a7aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "numerical_inp = 19\n",
    "\n",
    "X = df_result[[\n",
    "    'day_of_week', \n",
    "    'league_id', \n",
    "    'league_type_encoded',\n",
    "    'teams_home_id',\n",
    "    'teams_home_total_goals_scored',\n",
    "    'teams_home_total_goals_lost',\n",
    "    'teams_home_last_five_matches_points',\n",
    "    'teams_home_goals_scored_home',\n",
    "    'teams_home_goals_lost_home',\n",
    "    'teams_home_total_points',\n",
    "    'teams_home_standings',\n",
    "    'teams_away_id',\n",
    "    'teams_away_total_goals_scored',\n",
    "    'teams_away_total_goals_lost',\n",
    "    'teams_away_last_five_matches_points',\n",
    "    'teams_away_goals_scored_away',\n",
    "    'teams_away_goals_lost_away',\n",
    "    'teams_away_total_points',\n",
    "    'teams_away_standings'\n",
    "]]\n",
    "\n",
    "y_1 = df_result['result']\n",
    "y_2 = df_result['result_first_half']\n",
    "y_3 = df_result['result_double_chance_home']\n",
    "y_4 = df_result['result_double_chance_away']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615c38d2-5b7d-47ab-9072-edda75a2cd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'validation_split': 0.15,\n",
    "    'optimizer': 'adam',\n",
    "    'batch_size': 32,\n",
    "    'epochs': 10,\n",
    "    'learning_rate': 0.0015\n",
    "}\n",
    "\n",
    "b_result_model = define_rm_model()\n",
    "returned_params, returned_metrics, mod = training_rm(model=b_result_model, X=X, y_1=y_1, y_2=y_2, y_3=y_3, y_4=y_4, **params)\n",
    "returned_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
