{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e401f42c-560a-42ae-9605-6cbc80043338",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# add stats to fixtures table and save it in fixtures update table\n",
    "def future_engineering():\n",
    "    conn = None\n",
    "    cur = None\n",
    "    fixtures_df = None\n",
    "    conflict_columns = ['fixture_id']\n",
    "    db_params = {\n",
    "        'host': 'localhost',\n",
    "        'database': 'preds',\n",
    "        'user': 'postgres',\n",
    "        'password': 'pass',\n",
    "        'port': '5432'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        conn = None\n",
    "        cur = None \n",
    "    \n",
    "        conn = psycopg2.connect(**db_params)\n",
    "        cur = conn.cursor()\n",
    "        \n",
    "\n",
    "        query = \"\"\"\n",
    "            SELECT *\n",
    "            FROM fixtures\n",
    "            WHERE fixture_status_short IN ('FT', 'WO', 'AET', 'PEN', 'CANC')\n",
    "        \"\"\"\n",
    "        \n",
    "        fixtures_df = pd.read_sql_query(query, conn)\n",
    "        \n",
    "        df = add_statistics(fixtures_df)\n",
    "        \n",
    "        update_columns = [col for col in df.columns if col not in conflict_columns]\n",
    "        #insert data into tables\n",
    "\n",
    "        update_set = ', '.join([f\"{col} = EXCLUDED.{col}\" for col in update_columns])\n",
    "        insert_query = \"\"\"\n",
    "            INSERT INTO {} ({})\n",
    "            VALUES ({})\n",
    "            ON CONFLICT ({}) DO UPDATE SET {}\n",
    "        \"\"\".format('fixtures_updated', ','.join(df.columns), ','.join(['%s']*len(df.columns)), ','.join(conflict_columns), update_set)\n",
    "\n",
    "        cur.executemany(insert_query, df.values.tolist())\n",
    "        print(f'table fixtures_updated updated')\n",
    "        \n",
    "        # Commit the changes\n",
    "        conn.commit()\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f'Error {e}')\n",
    "        if conn is not None:\n",
    "            conn.rollback()\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            # Close the cursor and connection\n",
    "            cur.close()\n",
    "        if cur is not None:\n",
    "            conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1559b107-5e8e-4cd6-9baf-f50a82e2ba8b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def add_statistics(fixtures_df):\n",
    "    \n",
    "    fixtures_df['fixture_date'] = pd.to_datetime(fixtures_df['fixture_date']).dt.date\n",
    "    fixtures_df = fixtures_df.sort_values(by='fixture_date')\n",
    "    fixtures_df['teams_home_goals_scored_home'] = fixtures_df.groupby(['league_season', 'teams_home_id'])['goals_home'].cumsum()\n",
    "    fixtures_df['teams_away_goals_scored_away'] = fixtures_df.groupby(['league_season','teams_away_id'])['goals_away'].cumsum()\n",
    "    fixtures_df['teams_home_goals_lost_home'] = fixtures_df.groupby(['league_season','teams_home_id'])['goals_away'].cumsum()\n",
    "    fixtures_df['teams_away_goals_lost_away'] = fixtures_df.groupby(['league_season','teams_away_id'])['goals_home'].cumsum()\n",
    "    fixtures_df['teams_home_winner'] = fixtures_df.apply(\n",
    "        lambda row: 3 if row['score_fulltime_home']>row['score_fulltime_away'] else (1 if row['score_fulltime_home']==row['score_fulltime_away'] else 0), axis=1\n",
    "    )\n",
    "    fixtures_df['teams_away_winner'] = fixtures_df.apply(\n",
    "        lambda row: 3 if row['score_fulltime_home']<row['score_fulltime_away'] else (1 if row['score_fulltime_home']==row['score_fulltime_away'] else 0), axis=1\n",
    "    )\n",
    "    home = fixtures_df[[\n",
    "        'fixture_date',\n",
    "        'league_season',\n",
    "        'teams_home_id', \n",
    "        'goals_home',\n",
    "        'goals_away',\n",
    "        'teams_home_winner', \n",
    "        'league_round'\n",
    "        ]].rename(columns={\n",
    "        'teams_home_id':'team_id',\n",
    "        'goals_home':'goals_scored',\n",
    "        'goals_away':'goals_lost',\n",
    "        'teams_home_winner':'points'\n",
    "        })\n",
    "    away = fixtures_df[[\n",
    "        'fixture_date', \n",
    "        'league_season',\n",
    "        'teams_away_id', \n",
    "        'goals_away',\n",
    "        'goals_home',\n",
    "        'teams_away_winner', \n",
    "        'league_round'\n",
    "        ]].rename(columns={\n",
    "        'teams_away_id':'team_id', \n",
    "        'goals_away':'goals_scored',\n",
    "        'goals_home':'goals_lost',\n",
    "        'teams_away_winner':'points'\n",
    "        })\n",
    "\n",
    "    total = pd.concat([home, away])\n",
    "    total = total.sort_values(by='fixture_date')\n",
    "    total['total_goals_scored'] = total.groupby(['league_season','team_id'])['goals_scored'].cumsum()\n",
    "    total['total_goals_lost'] = total.groupby(['league_season','team_id'])['goals_lost'].cumsum()\n",
    "    total = total.sort_values(by='fixture_date')\n",
    "\n",
    "    total['total_points'] = total.groupby(['league_season','team_id'])['points'].cumsum()\n",
    "\n",
    "    total.sort_values(by=['league_season','league_round','total_points','total_goals_scored','fixture_date'], ascending=[True,True,False,False,True])\n",
    "    total['standings'] = total.groupby(['league_season','league_round'])['total_points'].rank(method='min', ascending=False)\n",
    "    total['standings'] = total['standings'].astype(int)\n",
    "\n",
    "    total = total.sort_values(by=['team_id','fixture_date'])\n",
    "    total['points_last_5_matches'] = total.groupby('team_id')['points'].rolling(window=5, min_periods=1).sum().reset_index(level=0, drop=True)\n",
    "    total['points_last_5_matches'] = total['points_last_5_matches'].fillna(0)\n",
    "    total['points_last_5_matches'] = total['points_last_5_matches'].astype(int)\n",
    "\n",
    "    fixtures_df = fixtures_df.merge(total[[\n",
    "        'fixture_date',\n",
    "        'team_id',\n",
    "        'total_goals_scored',\n",
    "        'total_goals_lost', \n",
    "        'points', \n",
    "        'total_points', \n",
    "        'standings',\n",
    "        'points_last_5_matches'\n",
    "        ]], left_on = [\n",
    "            'fixture_date',\n",
    "            'teams_home_id'\n",
    "            ],right_on = [\n",
    "            'fixture_date',\n",
    "            'team_id'\n",
    "            ], how='left'\n",
    "            ).rename(columns={\n",
    "                'total_goals_scored':'teams_home_total_goals_scored',\n",
    "                'total_goals_lost':'teams_home_total_goals_lost',\n",
    "                'points':'teams_home_points',\n",
    "                'total_points':'teams_home_total_points',\n",
    "                'standings':'teams_home_standings',\n",
    "                'points_last_5_matches':'teams_home_last_five_matches_points'\n",
    "            }).drop(columns='team_id')\n",
    "    \n",
    "    fixtures_df = fixtures_df.merge(total[[\n",
    "        'fixture_date',\n",
    "        'team_id',\n",
    "        'total_goals_scored',\n",
    "        'total_goals_lost', \n",
    "        'points', \n",
    "        'total_points', \n",
    "        'standings',\n",
    "        'points_last_5_matches'\n",
    "        ]], left_on = [\n",
    "            'fixture_date',\n",
    "            'teams_away_id'\n",
    "            ],right_on = [\n",
    "            'fixture_date',\n",
    "            'team_id'\n",
    "            ], how='left'\n",
    "            ).rename(columns={\n",
    "                'total_goals_scored':'teams_away_total_goals_scored',\n",
    "                'total_goals_lost':'teams_away_total_goals_lost',\n",
    "                'points':'teams_away_points',\n",
    "                'total_points':'teams_away_total_points',\n",
    "                'standings':'teams_away_standings',\n",
    "                'points_last_5_matches':'teams_away_last_five_matches_points'\n",
    "            }).drop(columns='team_id')\n",
    "\n",
    "    return fixtures_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4428911e-5f57-45e2-ac8f-15c04985bcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "df = future_engineering()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1d6ec2c5-ac5d-45cf-8469-e48683ee87d2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_matches(today, last_update):\n",
    "    \n",
    "    conn = None\n",
    "    db_params = {\n",
    "    'database' : 'preds',\n",
    "    'user' : 'postgres',\n",
    "    'password' : 'pass',\n",
    "    'host' : 'localhost',\n",
    "    'port' : '5432'}\n",
    "    #get next friday and monday dates as start and end for query\n",
    "    \n",
    "    # get upocoming matches playing from next friday to monday\n",
    "    try:\n",
    "        conn = psycopg2.connect(**db_params)\n",
    "\n",
    "        query = '''\n",
    "    SELECT a.* \n",
    "    FROM (\n",
    "        SELECT fu.*\n",
    "        FROM fixtures_updated fu\n",
    "        LEFT JOIN fixtures f ON fu.fixture_id = f.fixture_id\n",
    "        WHERE fixture_date >= '{}' and fixture_date <= '{}' and fixture_status_short IN ('FT', 'WO', 'AET', 'PEN', 'CANC')\n",
    "    ) a\n",
    "    RIGHT JOIN predictions p ON a.fixture_id = p.fixture_id\n",
    "    '''.format(last_update, today)\n",
    "        query2 = '''\n",
    "    SELECT p.*\n",
    "    FROM fixtures f\n",
    "    RIGHT JOIN predictions p ON f.fixture_id = p.fixture_id\n",
    "    WHERE fixture_date >= '{}' and fixture_date <= '{}' and fixture_status_short IN ('FT', 'WO', 'AET', 'PEN', 'CANC')\n",
    "    '''.format(last_update, today)\n",
    "        matches = pd.read_sql_query(query, conn)\n",
    "        predictions = pd.read_sql_query(query2, conn)\n",
    "        print('got  matches')\n",
    "        return matches, predictions\n",
    "    except Exception as e:\n",
    "        print(f'Error {e}')\n",
    "        return None, None\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "443b4b27-8a40-4412-9f71-6c0ac1dbcaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import date, timedelta\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a1ad8dd0-81b0-4eb7-9edf-ad01cae9949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_stats(df):\n",
    "    df['home_over_1'] = df.apply(lambda row: True if row['goals_home'] > 1 else False, axis=1)\n",
    "    df['home_over_2'] = df.apply(lambda row: True if row['goals_home'] > 2 else False, axis=1)\n",
    "    df['away_over_1'] = df.apply(lambda row: True if row['goals_away'] > 1 else False, axis=1)\n",
    "    df['away_over_2'] = df.apply(lambda row: True if row['goals_away'] > 2 else False, axis=1)\n",
    "    df['both_scores'] = df.apply(lambda row: True if (row['goals_home'] > 0)&(row['goals_away'] > 0) else False, axis=1)\n",
    "    df['result'] = df.apply(lambda row: 0 if row['goals_home'] > row['goals_away'] else (1 if row['goals_home'] == row['goals_away'] else 2), axis=1)\n",
    "    df['result_first_half'] = df.apply(lambda row: 0 if row['score_halftime_home'] > row['score_halftime_away'] else (1 if row['score_halftime_home'] == row['score_halftime_away'] else 2), axis=1)\n",
    "    df['result_double_chance_home'] = df.apply(lambda row: 1 if row['goals_home'] >= row['goals_away'] else 0, axis=1)\n",
    "    df['result_double_chance_away'] = df.apply(lambda row: 1 if row['goals_home'] <= row['goals_away'] else 0, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e9e06e23-ea5c-458a-9fff-29ebc72df7f4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olows\\AppData\\Local\\Temp\\ipykernel_14808\\2810923997.py:25: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  matches = pd.read_sql_query(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got  matches\n",
      "too little matches to update\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olows\\AppData\\Local\\Temp\\ipykernel_14808\\2810923997.py:26: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  predictions = pd.read_sql_query(query2, conn)\n"
     ]
    }
   ],
   "source": [
    "today = date.today()\n",
    "path = 'data/last_update.json'\n",
    "with open(path, 'r') as f:\n",
    "    last_update = json.load(f)\n",
    "date_format = '%Y-%m-%d'\n",
    "last_update = datetime.strptime(last_update, date_format).date()\n",
    "matches, predictions = get_matches(today, last_update)\n",
    "\n",
    "if len(matches) > 1000:\n",
    "    matches_stats = add_stats(matches)\n",
    "    \n",
    "    # goal model\n",
    "    goal_model = tf.keras.models.load_model('models/goal_model.h5')\n",
    "    \n",
    "    X = matches_stats[[\n",
    "        'day_of_week', \n",
    "        'league_id', \n",
    "        'league_type_encoded', \n",
    "        'teams_home_id', \n",
    "        'teams_home_total_goals_scored',\n",
    "        'teams_home_total_goals_lost', \n",
    "        'teams_home_last_five_matches_points',\n",
    "        'teams_home_goals_scored_home', \n",
    "        'teams_home_goals_lost_home',\n",
    "        'teams_away_id', \n",
    "        'teams_away_total_goals_scored',\n",
    "        'teams_away_total_goals_lost', \n",
    "        'teams_away_last_five_matches_points',\n",
    "        'teams_away_goals_scored_away', \n",
    "        'teams_away_goals_lost_away'\n",
    "    ]]\n",
    "    y_1 = df_goals['home_over_1']\n",
    "    y_2 = df_goals['home_over_2']\n",
    "    y_3 = df_goals['away_over_1']\n",
    "    y_4 = df_goals['away_over_2']\n",
    "    y_5 = df_goals['both_scores']\n",
    "    \n",
    "    # Fine-tune the model using only the new data\n",
    "    params = {\n",
    "        'learning_rate': 0.001,\n",
    "        'epochs': 10,\n",
    "        'batch_size': 32,\n",
    "        'validation_split': 0.2\n",
    "    }\n",
    "    \n",
    "    params_list, metrics_list, updated_model = training(\n",
    "        goal_model, \n",
    "        X, \n",
    "        y_1, \n",
    "        y_2, \n",
    "        y_3, \n",
    "        y_4, \n",
    "        y_5, \n",
    "        **params\n",
    "    )\n",
    "    updated_model.save('models/goal_model.h5')\n",
    "    \n",
    "    # result model\n",
    "    X = matches_stats[[\n",
    "        'day_of_week', \n",
    "        'league_id', \n",
    "        'league_type_encoded',\n",
    "        'teams_home_id',\n",
    "        'teams_home_total_goals_scored',\n",
    "        'teams_home_total_goals_lost',\n",
    "        'teams_home_last_five_matches_points',\n",
    "        'teams_home_goals_scored_home',\n",
    "        'teams_home_goals_lost_home',\n",
    "        'teams_home_total_points',\n",
    "        'teams_home_standings',\n",
    "        'teams_away_id',\n",
    "        'teams_away_total_goals_scored',\n",
    "        'teams_away_total_goals_lost',\n",
    "        'teams_away_last_five_matches_points',\n",
    "        'teams_away_goals_scored_away',\n",
    "        'teams_away_goals_lost_away',\n",
    "        'teams_away_total_points',\n",
    "        'teams_away_standings'\n",
    "    ]]\n",
    "    \n",
    "    y_1 = df_result['result']\n",
    "    y_2 = df_result['result_first_half']\n",
    "    y_3 = df_result['result_double_chance_home']\n",
    "    y_4 = df_result['result_double_chance_away']\n",
    "    \n",
    "    result_model = tf.keras.models.load_model('models/result_model.h5')\n",
    "    \n",
    "    # Fine-tune the model using only the new data\n",
    "    params = {\n",
    "        'learning_rate': 0.001,\n",
    "        'epochs': 10,\n",
    "        'batch_size': 32,\n",
    "        'validation_split': 0.2\n",
    "    }\n",
    "    \n",
    "    params_list, metrics_list, updated_model = training(\n",
    "        result_model, \n",
    "        X_new, \n",
    "        y_1_new, \n",
    "        y_2_new, \n",
    "        y_3_new, \n",
    "        y_4_new, \n",
    "        y_5_new, \n",
    "        **params\n",
    "    )\n",
    "    updated_model.save('models/result_model.h5')\n",
    "    \n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(str(last_update), f)\n",
    "else:\n",
    "    print('too little matches to update')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
