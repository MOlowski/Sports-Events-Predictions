{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "95fadab1-4bd4-4f0a-95b4-23d37ff40360",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_data(endpoint, params):\n",
    "    \n",
    "    URL = \"https://v3.football.api-sports.io/\"\n",
    "    headers = {\n",
    "\t'x-rapidapi-host': \"v3.football.api-sports.io\",\n",
    "    'x-rapidapi-key': \"fb2140228973d644db847895c454c22b\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(\n",
    "        URL+endpoint,\n",
    "        headers = headers,\n",
    "        params = params\n",
    "    )\n",
    "    if response.status_code == 200:\n",
    "            \n",
    "        remaining = response.headers.get(\"x-ratelimit-requests-remaining\")\n",
    "        data = response.json()\n",
    "        print(f\"requests before reaching limit {remaining}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Error {response.status_code}, {response.text}\")\n",
    "\n",
    "    return data, remaining                                                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4eb9b678-f7f2-499b-83b4-1469fec1c71c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def encode_data(data_dict, parent_key = '', sep= '_'):\n",
    "    encoded = []\n",
    "    for key, val in data_dict.items():\n",
    "        new_key = f'{parent_key}{sep}{key}' if parent_key else key\n",
    "        if isinstance(val, dict):\n",
    "            encoded.extend(encode_data(val, new_key, sep=sep).items())\n",
    "        elif isinstance(val, list):\n",
    "            if val:\n",
    "                if all(isinstance(i, dict) for i in val):\n",
    "                    for k, v in enumerate(val):\n",
    "                        v_key = f'{new_key}{sep}{k}'\n",
    "                        encoded.extend(encode_data(v, v_key, sep=sep).items())\n",
    "                else:\n",
    "                    encoded.append((new_key, val))\n",
    "            else:\n",
    "                encoded.append((new_key, []))\n",
    "        else:\n",
    "            encoded.append((new_key, val))\n",
    "    return dict(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e18f99b-84fc-4651-8497-4465b0b590d9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def encode_fix_stats(data, fixture_id):\n",
    "    encoded = []\n",
    "    encoded.append(('fixture_id', fixture_id))\n",
    "    for key, val in data.items():\n",
    "        if key =='team':\n",
    "            encoded.append((key+'_id', val['id']))\n",
    "        else:\n",
    "            for el in val:\n",
    "                encoded.append((el['type'].lower().replace(' ', '_').replace('%', 'percentage'), el['value']))\n",
    "    return dict(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8c2906b9-f8b7-4ed3-9588-a9679edb8ffd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def data_to_sql(table_name, df, db_params, conflict_columns, update_columns):\n",
    "    conn = None\n",
    "    cur = None\n",
    "    try:\n",
    "        # Establish the connection\n",
    "        conn = psycopg2.connect(**db_params)\n",
    "        cur = conn.cursor()\n",
    "        \n",
    "        #insert data into tables\n",
    "        if len(conflict_columns) == 0:\n",
    "            insert_query = \"\"\"\n",
    "                INSERT INTO {} ({})\n",
    "                VALUES ({})\n",
    "            \"\"\".format(table_name, ','.join(df.columns), ','.join(['%s']*len(df.columns)))\n",
    "        else:\n",
    "            if update_columns:\n",
    "                update_set = ', '.join([f\"{col} = EXCLUDED.{col}\" for col in update_columns])\n",
    "                insert_query = \"\"\"\n",
    "                    INSERT INTO {} ({})\n",
    "                    VALUES ({})\n",
    "                    ON CONFLICT ({}) DO UPDATE SET {}\n",
    "                \"\"\".format(table_name, ','.join(df.columns), ','.join(['%s']*len(df.columns)), ','.join(conflict_columns), update_set)\n",
    "            else:\n",
    "                insert_query = \"\"\"\n",
    "                    INSERT INTO {} ({})\n",
    "                    VALUES ({})\n",
    "                    ON CONFLICT ({}) DO NOTHING\n",
    "                \"\"\".format(table_name, ','.join(df.columns), ','.join(['%s']*len(df.columns)), ','.join(conflict_columns))\n",
    "\n",
    "        # Execute insert query for each row\n",
    "        for row in df.itertuples(index=False, name=None):\n",
    "            cur.execute(insert_query, row)\n",
    "        \n",
    "        # Commit the transaction\n",
    "        conn.commit()       \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            # Close the cursor and connection\n",
    "            cur.close()\n",
    "        if cur is not None:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ba3c5f2f-c848-4c0a-aad2-78b095f0c3b9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_last_date(db_params, today):\n",
    "    get_data_query = '''\n",
    "    SELECT fixture_id\n",
    "    FROM fixtures \n",
    "    WHERE fixture_status_short != 'FT' and fixture_status_short != 'WO' and fixture_status_short != 'AET' and fixture_status_short != 'PEN' and fixture_status_short != 'CANC' and fixture_date < today\n",
    "    '''\n",
    "    res = []\n",
    "    conn = None\n",
    "    cur = None\n",
    "    try:\n",
    "        # Establish the connection\n",
    "        conn = psycopg2.connect(**db_params)\n",
    "        cur = conn.cursor()\n",
    "        \n",
    "        cur.execute(get_data_query)\n",
    "        \n",
    "        res = [row[0] for row in cur.fetchall()]\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        if last_row is not None:\n",
    "            print(f\"Last row loaded before the error occurred: {last_row}\")\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            # Close the cursor and connection\n",
    "            cur.close()\n",
    "        if cur is not None:\n",
    "            conn.close()\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "739d08bb-dc68-4f2b-8300-3d2d7608b590",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_teams(teams, df):\n",
    "    for row in df:\n",
    "        to_add_1 = {'league': row['league']['id'], 'season': row['league']['season'], 'team': row['teams']['home']['id']}\n",
    "        to_add_2 = {'league': row['league']['id'], 'season': row['league']['season'], 'team': row['teams']['away']['id']}\n",
    "        teams.extend([to_add_1, to_add_2])\n",
    "    return teams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9b9e82-495c-440a-bb3c-35b1ad0a44c9",
   "metadata": {},
   "source": [
    "##### Get fixtures and their stats played during collecting historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0248ccd-b443-4d2e-b5bf-a7d051026ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import date\n",
    "\n",
    "remaining = 100\n",
    "fixtures_data = []\n",
    "fixture_stats_data = []\n",
    "teams_to_update = []\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "bucket_name = 'sport-storage'\n",
    "matches_key = 'total_fixs.json'\n",
    "teams_to_u = 'teams_to_update.csv'\n",
    "\n",
    "matches_response = s3.get_object(Bucket = bucket_name, Key = matches_key)\n",
    "teams_to_upd = s3.get_object(Bucket = bucket_name, Key = teams_to_upd)\n",
    "total_fixs = pickle.loads(matches_response['Body'].read())\n",
    "teams_update = pd.read_csv(io.BytesIO(missed['Body'].read()))\n",
    "\n",
    "if len(total_fixs) == 0:\n",
    "    today = date.today()\n",
    "    fixtures_to_find = get_last_date(db_params, today)\n",
    "    total_fixs = fixtures_to_find\n",
    "else:\n",
    "    fixtures_to_find = total_fixs\n",
    "    \n",
    "while (remaining > 0) & (len(fixtures_to_find) > 0):\n",
    "    \n",
    "    ids = ''\n",
    "    sep = '-'\n",
    "    # get fixtures ids to find\n",
    "    if len(fixtures_to_find) > 20:\n",
    "        for i in range(0,20):\n",
    "            ids = f'{ids}{sep}{fixtures_to_find[i]}' if ids else fixtures_to_find[i]\n",
    "        fixtures_to_find = fixtures_to_find[20:]\n",
    "    \n",
    "    elif len(fixtures_to_find) > 0:\n",
    "        for i in fixtures_to_find:\n",
    "            ids = f'{ids}{sep}{i}' if ids else i\n",
    "        fixtures_to_find = []\n",
    "    \n",
    "    #get fixtures\n",
    "    if ids:      \n",
    "        params = {'ids': ids}\n",
    "        \n",
    "        df, remaining = get_data('fixtures', params)\n",
    "        if len(df['response']) > 0:\n",
    "            fixtures_data.extend(encode_data(row) for row in df['response'])\n",
    "            teams_to_update = get_teams(teams_to_update, df['response']))\n",
    "        \n",
    "while (remaining > 0) & (len(total_fixs) > 0):\n",
    "\n",
    "    params = {'fixture': total_fixs[0]}\n",
    "    df, remaining = get_data('fixtures/statistics', params)\n",
    "    fixture_stats_data.extend(encode_fix_stats(df['response'], total_fixs[0]))\n",
    "    total_fixs.pop(0)\n",
    "\n",
    "if len(fixtures_data) > 0:\n",
    "    fixtures_df = pd.DataFrame(fixtures_data)\n",
    "    fixtures_df = fixtures_df.drop(columns = {\n",
    "        'league_name',\n",
    "        'league_country',\n",
    "        'league_logo',\n",
    "        'league_flag',\n",
    "        'fixture_venue_city',\n",
    "        'fixture_venue_name',\n",
    "        'teams_away_logo',\n",
    "        'teams_away_name',\n",
    "        'teams_home_logo',\n",
    "        'teams_home_name'})\n",
    "    conflict_col = ['fixture_id']\n",
    "    update_col = list(fixtures_df.columns)\n",
    "    data_to_sql('fixtures', fixtures_df, db_params, conflict_col, update_col)\n",
    "    \n",
    "if len(fixture_stats_data) > 0:\n",
    "    fixture_stats_df = pd.DataFrame(fixture_stats_data)\n",
    "    conflict_col = ['fixture_id', 'team_id']\n",
    "    update_col = list(fixture_stats_df.columns)\n",
    "    data_to_sql('fixture_statistics', fixture_stats_df, db_params, conflict_col, update_col)\n",
    "\n",
    "teams_update_df = pd.DataFrame(teams_to_update).drop_duplicates()\n",
    "teams_update = pd.concat(teams_update_df, teams_update)\n",
    "\n",
    "csv_buffer = io.StringIO()\n",
    "teams_update.to_csv(csv_buffer, index=False)\n",
    "s3.put_object(Bucket = bucket_name, Key = object_key1, Body=csv_buffer.getvalue().encode())\n",
    "\n",
    "json_data = json.dump(total_fixs)\n",
    "s3.put_object(Bucket = bucket_name, Key = teams_to_upd, Body=json_data)\n",
    "\n",
    "if len(total_fixs) == 0:\n",
    "    print('fixture data is actual')\n",
    "## update team stats and fixs stats \n",
    "## get fixs to update from list total_fix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34adbb47-8cbf-40ad-87f7-482ca26a35d3",
   "metadata": {},
   "source": [
    "##### Get team stats before starting predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd830db-7a77-45b8-b8f5-4e03a8af8daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import date\n",
    "\n",
    "remaining = 100\n",
    "total_team_stats_data = []\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "bucket_name = 'sport-storage'\n",
    "teams_to_u = 'teams_to_update.csv'\n",
    "\n",
    "teams_to_upd = s3.get_object(Bucket = bucket_name, Key = teams_to_upd)\n",
    "teams_update = pd.read_csv(io.BytesIO(missed['Body'].read()))\n",
    "\n",
    "to_find == 'teams/statistics'\n",
    "\n",
    "if len(teams_update)>0:\n",
    "    done = False\n",
    "else:\n",
    "    done = True\n",
    "    \n",
    "while (done==False)&(remaining > 0):\n",
    "    team = team_update.loc[0]\n",
    "    params = {'league': team['league'],\n",
    "              'season': team['season'],\n",
    "              'team': team['team']\n",
    "             }\n",
    "    endpoint = to_find\n",
    "    data, remaining_req = get_data(endpoint, params)\n",
    "    total_team_stats_data.append(encode_data(data['response']))\n",
    "        \n",
    "        # drop team that data was already collected for\n",
    "    if len(teams_update) > 0:\n",
    "        team_update = team_update.loc[1:]\n",
    "\n",
    "        # if data for all seasons were collected quit loop\n",
    "    else:\n",
    "        done = True\n",
    "                    \n",
    "    remaining = int(remaining_req)\n",
    "    print(remaining)\n",
    "    # sleep cause there can be done only 10 requests per minute\n",
    "    time.sleep(7)\n",
    "db_params = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'preds',\n",
    "    'user': 'postgres',\n",
    "    'password': 'pass',\n",
    "    'port': '5432'\n",
    "}\n",
    "if len(total_team_stats_data) > 0:\n",
    "    team_stats_df = pd.DataFrame(total_team_stats_data)\n",
    "    team_stats_df = team_stats_df.drop(columns = {\n",
    "        'league_name', \n",
    "        'league_country', \n",
    "        'league_logo', \n",
    "        'league_flag', \n",
    "        'team_name', \n",
    "        'team_logo',\n",
    "        'lineups'})\n",
    "    team_stats_df = team_stats_df.fillna(0)\n",
    "    conflict_col = ['league_id', 'team_id']\n",
    "    update_col = list(team_stats_df.columns)\n",
    "    team_stats_df.columns = team_stats_df.columns.str.replace('-','_')\n",
    "    data_to_sql('team_stats', team_stats_df, db_params, conflict_col, update_col)\n",
    "    \n",
    "csv_buffer = io.StringIO()\n",
    "teams_update.to_csv(csv_buffer, index=False)\n",
    "s3.put_object(Bucket = bucket_name, Key = object_key1, Body=csv_buffer.getvalue().encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28281429-7bf4-4db1-bd57-5649296be28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "1. get all historical data,\n",
    "2. then find last results date and if season is current get missing results, team stats,\n",
    "\n",
    "7 days matches\n",
    "\n",
    "3. start collecting data about upcoming matches in next 7 days,\n",
    "4. create predictions model,\n",
    "5. create table for predictions and actual results,\n",
    "6. after that 7 days get real result and save them in fixtures and preds table,\n",
    "7. decide whats better add results to team stats table or collect latest data about team stats (??),\n",
    "8. use preds and real results for models' training,\n",
    "9. create flask app to display preds,\n",
    "10. get upcoming fixtures odds and compare them to preds,\n",
    "11. filter odds worth betting,\n",
    "12. display that bets on flask api\n",
    "13. display statistics for that bets,\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
