{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c7f0bc38-6fc4-42ca-888b-7aa1b21f3431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_matches(start_date, end_date):\n",
    "    \n",
    "    conn = None\n",
    "    db_params = {\n",
    "        'host': 'localhost',\n",
    "        'database': 'preds',\n",
    "        'user': 'postgres',\n",
    "        'password': 'pass',\n",
    "        'port': '5432'\n",
    "    }\n",
    "    #get next friday and monday dates as start and end for query\n",
    "\n",
    "    # get upocoming matches playing from next friday to monday\n",
    "    try:\n",
    "        conn = psycopg2.connect(**db_params)\n",
    "\n",
    "        query = '''\n",
    "    SELECT a.*\n",
    "    FROM (\n",
    "        SELECT p.*, f.league_id, fixture_date\n",
    "        FROM predictions p\n",
    "        JOIN fixtures f ON p.fixture_id = f.fixture_id\n",
    "        WHERE f.fixture_date >= '{}' and fixture_date <= '{}'\n",
    "    ) a\n",
    "    LEFT JOIN odds o ON a.fixture_id = o.fixture_id\n",
    "    WHERE o.fixture_id IS NULL;\n",
    "    '''.format(start_date, end_date)\n",
    "        current_matches = pd.read_sql_query(query, conn)\n",
    "        \n",
    "        return current_matches\n",
    "    except Exception as e:\n",
    "        print(f'Error {e}')\n",
    "        return None, None\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eed89dbb-582d-4884-94c3-6a8d28ef66fa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "\n",
    "def get_data(endpoint, params):\n",
    "    \n",
    "    load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "    api_key = os.getenv('API_KEY')\n",
    "\n",
    "    if api_key is None:\n",
    "        raise ValueError(\"API key not set.\")\n",
    "\n",
    "    URL = \"https://v3.football.api-sports.io/\"\n",
    "    headers = {\n",
    "\t'x-rapidapi-host': \"v3.football.api-sports.io\",\n",
    "    'x-rapidapi-key': api_key\n",
    "    }\n",
    "    response = requests.get(\n",
    "        URL+endpoint,\n",
    "        headers = headers,\n",
    "        params = params\n",
    "    )\n",
    "    if response.status_code == 200:\n",
    "            \n",
    "        remaining = response.headers.get(\"x-ratelimit-requests-remaining\")\n",
    "        data = response.json()\n",
    "        print(f\"requests before reaching limit {remaining}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Error {response.status_code}, {response.text}\")\n",
    "\n",
    "    return data, remaining                                                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "85ebe1bf-1d47-4d89-b1fe-2ca09b435a2e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def encode_data(data_dict, parent_key = '', sep= '_'):\n",
    "    encoded = []\n",
    "    for key, val in data_dict.items():\n",
    "        new_key = f'{parent_key}{sep}{key}' if parent_key else key\n",
    "        if isinstance(val, dict):\n",
    "            encoded.extend(encode_data(val, new_key, sep=sep).items())\n",
    "        elif isinstance(val, list):\n",
    "            if val:\n",
    "                if all(isinstance(i, dict) for i in val):\n",
    "                    for k, v in enumerate(val):\n",
    "                        v_key = f'{new_key}{sep}{k}'\n",
    "                        encoded.extend(encode_data(v, v_key, sep=sep).items())\n",
    "                else:\n",
    "                    encoded.append((new_key, val))\n",
    "            else:\n",
    "                encoded.append((new_key, []))\n",
    "        else:\n",
    "            encoded.append((new_key, val))\n",
    "    return dict(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "827a1eaa-3a63-4020-a580-872862fcc31a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def data_to_sql(table_name, df, db_params, conflict_columns):\n",
    "    conn = None\n",
    "    cur = None\n",
    "    try:\n",
    "        # Establish the connection\n",
    "        conn = psycopg2.connect(**db_params)\n",
    "        cur = conn.cursor()\n",
    "        \n",
    "        #insert data into tables\n",
    "        if len(conflict_columns) == 0:\n",
    "            insert_query = \"\"\"\n",
    "                INSERT INTO {} ({})\n",
    "                VALUES ({})\n",
    "            \"\"\".format(table_name, ','.join(df.columns), ','.join(['%s']*len(df.columns)))\n",
    "        else:\n",
    "            insert_query = \"\"\"\n",
    "                INSERT INTO {} ({})\n",
    "                VALUES ({})\n",
    "                ON CONFLICT ({}) DO NOTHING\n",
    "            \"\"\".format(table_name, ','.join(df.columns), ','.join(['%s']*len(df.columns)), ','.join(conflict_columns))\n",
    "        if len(df) > 0:\n",
    "            last_row = df.iloc[-1]\n",
    "        cur.executemany(insert_query, df.values.tolist())\n",
    "        print(f'table {table_name} updated')\n",
    "        \n",
    "        # Commit the changes\n",
    "        conn.commit()\n",
    "        \n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        if last_row is not None:\n",
    "            print(f\"Last row loaded before the error occurred: {last_row}\")\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            # Close the cursor and connection\n",
    "            cur.close()\n",
    "        if cur is not None:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "003482bc-b058-4c37-916a-6387e227affd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(odd_data):\n",
    "    \n",
    "    all_filtered_data = []\n",
    "    for index, data in enumerate(odd_data):\n",
    "        books = [len(book['bets']) for book in odd_data[index]['bookmakers']]\n",
    "        bb = books.index(max(books))\n",
    "        data = encode_data(data)\n",
    "        filtered_data = {}\n",
    "        filtered_data['fixture_id'] = data['fixture_id']\n",
    "        for key, value in data.items():\n",
    "            if value == 'Match Winner':\n",
    "                match = re.search(fr'bookmakers_{bb}_bets_(\\d+)_name', key)\n",
    "                if match:\n",
    "                    bet_number = match.group(1)\n",
    "                    filtered_data['result_home'] = data[f'bookmakers_{bb}_bets_{bet_number}_values_0_odd']\n",
    "                    filtered_data['result_draw'] = data[f'bookmakers_{bb}_bets_{bet_number}_values_1_odd']\n",
    "                    filtered_data['result_away'] = data[f'bookmakers_{bb}_bets_{bet_number}_values_2_odd']\n",
    "            if value == 'Both Teams Score':\n",
    "                match = re.search(fr'bookmakers_{bb}_bets_(\\d+)_name', key)\n",
    "                if match:\n",
    "                    bet_number = match.group(1)\n",
    "                    filtered_data['both_scores_true'] = data[f'bookmakers_{bb}_bets_{bet_number}_values_0_odd']\n",
    "                    filtered_data['both_scores_false'] = data[f'bookmakers_{bb}_bets_{bet_number}_values_1_odd']\n",
    "            if value == 'Double Chance':\n",
    "                match = re.search(fr'bookmakers_{bb}_bets_(\\d+)_name', key)\n",
    "                if match:\n",
    "                    bet_number = match.group(1)\n",
    "                    if data[f'bookmakers_{bb}_bets_{bet_number}_values_0_value'] == 'Home/Draw':\n",
    "                        filtered_data['double_chance_home'] = data[f'bookmakers_{bb}_bets_{bet_number}_values_0_odd']\n",
    "                    elif data[f'bookmakers_{bb}_bets_{bet_number}_values_0_value'] == 'Draw/Away':\n",
    "                        filtered_data['double_chance_away'] = data[f'bookmakers_{bb}_bets_{bet_number}_values_0_odd']\n",
    "                    if (f'bookmakers_{bb}_bets_{bet_number}_values_1_odd' in data) & (data[f'bookmakers_{bb}_bets_{bet_number}_values_1_value'] == 'Draw/Away'):\n",
    "                            filtered_data['double_chance_away'] = data[f'bookmakers_{bb}_bets_{bet_number}_values_1_odd']\n",
    "                    if f'bookmakers_{bb}_bets_{bet_number}_values_2_odd' in data:\n",
    "                        filtered_data['double_chance_away'] = data[f'bookmakers_{bb}_bets_{bet_number}_values_2_odd']                        \n",
    "            if value == 'First Half Winner':\n",
    "                match = re.search(fr'bookmakers_{bb}_bets_(\\d+)_name', key)\n",
    "                if match:\n",
    "                    bet_number = match.group(1)\n",
    "                    filtered_data['fh_result_home'] = data[f'bookmakers_{bb}_bets_{bet_number}_values_0_odd']\n",
    "                    filtered_data['fh_result_draw'] = data[f'bookmakers_{bb}_bets_{bet_number}_values_1_odd']\n",
    "                    filtered_data['fh_result_away'] = data[f'bookmakers_{bb}_bets_{bet_number}_values_2_odd']\n",
    "            if value == 'Total - Home':\n",
    "                match = re.search(fr'bookmakers_{bb}_bets_(\\d+)_name', key)\n",
    "                if match:\n",
    "                    bet_number = match.group(1)\n",
    "                    filtered_data['home_over_1'] = data[f'bookmakers_{bb}_bets_{bet_number}_values_0_odd']\n",
    "                    filtered_data['home_over_2'] = data[f'bookmakers_{bb}_bets_{bet_number}_values_2_odd']\n",
    "            if value == 'Total - Away':\n",
    "                match = re.search(fr'bookmakers_{bb}_bets_(\\d+)_name', key)\n",
    "                if match:\n",
    "                    bet_number = match.group(1)\n",
    "                    filtered_data['away_over_1'] = data[f'bookmakers_{bb}_bets_{bet_number}_values_0_odd']\n",
    "                    filtered_data['away_over_2'] = data[f'bookmakers_{bb}_bets_{bet_number}_values_2_odd']\n",
    "                    \n",
    "            cols = ['result_home', 'result_draw', \n",
    "                    'result_away', 'both_scores_true', \n",
    "                    'both_scores_false', 'double_chance_home', \n",
    "                    'double_chance_away', 'fh_result_home', \n",
    "                    'fh_result_draw', 'fh_result_away', \n",
    "                    'home_over_1', 'home_over_2', \n",
    "                    'away_over_1', 'away_over_2']\n",
    "        for col in cols:\n",
    "            if col not in filtered_data:\n",
    "                filtered_data[col] = 0\n",
    "        all_filtered_data.append(filtered_data)\n",
    "    df = pd.DataFrame(all_filtered_data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6fb879ca-4e7f-4a4c-9fa5-01b957118fe4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olows\\AppData\\Local\\Temp\\ipykernel_14352\\542875382.py:28: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  current_matches = pd.read_sql_query(query, conn)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "import datetime\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "t = date.today()\n",
    "start_date = t\n",
    "while start_date.weekday() != 4:\n",
    "    if start_date.weekday() < 4:\n",
    "        start_date += datetime.timedelta(1)\n",
    "    else:\n",
    "        start_date -= datetime.timedelta(1)\n",
    "end_date = start_date\n",
    "while end_date.weekday() != 0:\n",
    "    end_date += datetime.timedelta(1)\n",
    "\n",
    "matches = get_predicted_matches(start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "df27e200-a2e1-4cce-bad4-55545597cd4b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requests before reaching limit 7174\n",
      "requests before reaching limit 7173\n",
      "requests before reaching limit 7172\n",
      "requests before reaching limit 7171\n",
      "requests before reaching limit 7170\n",
      "requests before reaching limit 7169\n",
      "requests before reaching limit 7168\n",
      "requests before reaching limit 7167\n",
      "requests before reaching limit 7166\n",
      "requests before reaching limit 7165\n",
      "requests before reaching limit 7164\n",
      "requests before reaching limit 7163\n",
      "requests before reaching limit 7162\n",
      "requests before reaching limit 7161\n",
      "requests before reaching limit 7160\n",
      "requests before reaching limit 7159\n",
      "requests before reaching limit 7158\n",
      "requests before reaching limit 7157\n",
      "requests before reaching limit 7156\n",
      "requests before reaching limit 7155\n",
      "requests before reaching limit 7154\n",
      "requests before reaching limit 7153\n",
      "requests before reaching limit 7152\n",
      "requests before reaching limit 7151\n",
      "requests before reaching limit 7150\n",
      "requests before reaching limit 7149\n",
      "requests before reaching limit 7148\n",
      "requests before reaching limit 7147\n",
      "requests before reaching limit 7146\n",
      "requests before reaching limit 7145\n",
      "requests before reaching limit 7144\n",
      "requests before reaching limit 7143\n",
      "requests before reaching limit 7142\n",
      "requests before reaching limit 7141\n",
      "requests before reaching limit 7140\n",
      "requests before reaching limit 7139\n",
      "requests before reaching limit 7138\n",
      "requests before reaching limit 7137\n",
      "requests before reaching limit 7136\n",
      "requests before reaching limit 7135\n",
      "requests before reaching limit 7134\n",
      "requests before reaching limit 7133\n",
      "requests before reaching limit 7132\n",
      "requests before reaching limit 7131\n",
      "requests before reaching limit 7130\n",
      "requests before reaching limit 7129\n",
      "requests before reaching limit 7128\n",
      "requests before reaching limit 7127\n",
      "requests before reaching limit 7126\n",
      "requests before reaching limit 7125\n",
      "requests before reaching limit 7124\n",
      "requests before reaching limit 7123\n",
      "requests before reaching limit 7122\n",
      "requests before reaching limit 7121\n",
      "requests before reaching limit 7120\n",
      "requests before reaching limit 7119\n",
      "requests before reaching limit 7118\n",
      "requests before reaching limit 7117\n",
      "requests before reaching limit 7116\n",
      "requests before reaching limit 7115\n",
      "requests before reaching limit 7114\n",
      "requests before reaching limit 7113\n",
      "requests before reaching limit 7112\n",
      "requests before reaching limit 7111\n",
      "True\n",
      "1195620\n",
      "1195621\n",
      "1195622\n",
      "1195623\n",
      "1195624\n",
      "1184904\n",
      "1184905\n",
      "1184906\n",
      "1184907\n",
      "1184908\n",
      "1184909\n",
      "1179037\n",
      "1179038\n",
      "1152186\n",
      "1152187\n",
      "1152188\n",
      "1152189\n",
      "1152190\n",
      "1164790\n",
      "1164791\n",
      "1164792\n",
      "1164793\n",
      "1164794\n",
      "1164795\n",
      "1164796\n",
      "1164638\n",
      "1164639\n",
      "1164640\n",
      "1164641\n",
      "1164642\n",
      "1164643\n",
      "1175394\n",
      "1152827\n",
      "1152828\n",
      "1199407\n",
      "1199408\n",
      "1199409\n",
      "1199410\n",
      "1179229\n",
      "1179225\n",
      "1179228\n",
      "1179231\n",
      "1179226\n",
      "1179227\n",
      "1179230\n"
     ]
    }
   ],
   "source": [
    "#get only matches with odds available\n",
    "c = pd.read_csv('data/european_seasons.csv')\n",
    "matches = matches.merge(c[['league_id','odds']], on='league_id')\n",
    "matches = matches[matches['odds']]\n",
    "matches_list = list(matches['fixture_id'].unique())\n",
    "leagues_list = list(matches['league_id'].unique())\n",
    "    \n",
    "odds_data = []\n",
    "remaining = 10000\n",
    "done = False\n",
    "date = start_date\n",
    "page = 1\n",
    "\n",
    "while remaining > 0 and not done:\n",
    "    season = list(c[c['league_id']==leagues_list[0]]['year'])[-1]\n",
    "    params = {'league':leagues_list[0],\n",
    "              'date':date,\n",
    "              'season':season,\n",
    "              'page':page}\n",
    "    response, remaining = get_data('odds', params)    \n",
    "    if page != response['paging']['total']:\n",
    "        page += 1\n",
    "    else:\n",
    "        page = 1\n",
    "        if date != end_date:\n",
    "            date += datetime.timedelta(1)\n",
    "        else:\n",
    "            date = start_date\n",
    "            leagues_list.pop(0)\n",
    "        \n",
    "    if len(response['response'])>0:\n",
    "        odds_data.extend(match for match in response['response'])\n",
    "    \n",
    "    remaining = int(remaining)\n",
    "    done = True if len(leagues_list)==0 else False\n",
    "    \n",
    "print(done)\n",
    "if len(odds_data) > 0:\n",
    "    # preprocess data\n",
    "    df = preprocess_data(odds_data)\n",
    "    # send to db\n",
    "    #data_to_sql('odds', df, params, 'fixture_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4474ded4-c721-4f20-91bb-9b4d41c74470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(odds_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "20e6dafe-cae8-4f9f-bf94-999fab7c2b7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = preprocess_data(odds_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "004783d6-f0cd-4679-bf42-26314f72f2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requests before reaching limit 497\n"
     ]
    }
   ],
   "source": [
    "a, b = get_data('odds', {'fixture': 1132615})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a0e13f9c-6c53-4186-be52-6395ed7f25fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c = encode_data(a['response'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c1712bbb-5601-43fa-bb8a-5bda2ca22de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "25\n",
      "23\n",
      "15\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for b in a['response'][0]['bookmakers']:\n",
    "    print(len(b['bets']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17920de1-4af7-4bd9-9135-123ecf6ea657",
   "metadata": {},
   "source": [
    "### Preprocces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f0c397-9be9-47a1-96e0-673919f4d4e2",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
